"""
Purpose:
The following module is the 'data processor'. It is responsible for
processing the data recieved from the data generator, and handing over the
cleaned data in a consistent format to the data visualizer module.

Date: 5/26/2020

Author: Lauren Heintz
"""

import pandas as pd


class DataProcessor:
    """
    The DataProcessor class is used to prep the data recieved from the
    DataGenerator and pass it to the DataVisualizer. It has 4 attributes.

    args: the keyword arguments recieved from the user
    input_data_frames: the two input dataframes of covid data and
                        google trends data as generated by the DataGenerator
    clean_data_frame: a cbasic cleaned version of the two input data frames
                        before additional processing at an aggregate level
    agg_data_frame: a single dataframe containing all the data from both data
                    sets joined on the date. The data is cleaned then to
                    address gaps that arise from the data join
    """
    def __init__(self, args, data_frames=[]):
        self.args = args
        self.input_data_frames = data_frames
        self.clean_data_frame = None
        self.agg_data_frame = None

    def run(self):
        """
        This function executes all the other functions in this module to
        accomplish the data cleaning steps.
        """
        self.clean_data(self.input_data_frames)
        self.aggregate_data()

    def clean_data(self, data_frames=[]):
        """
        This function does some basic clean up of both the COVID data
        and Google Trends data. For instance, renaming columns
        for consistency and dropping unused columns.
        Inputs:
            - data_frames: An array of the two dataframes with the first being
            covid data and the second being trend data
        Outputs:
            - clean_data_frame: An array of the two dataframes post-cleaning
            with the first being covid data and the second being trend data
        """
        # Variable Assignment
        covid = data_frames[0]
        trend = data_frames[1]

        # Clean up covid columns
        covid = covid.drop(columns=['ID', 'Latitude', 'Longitude', 'ISO2',
                                    'ISO3', 'AdminRegion2'])
        covid = covid.rename(columns={'Updated': 'Date',
                                      'Country_Region': 'Country',
                                      'AdminRegion1': 'State'})

        covid['Date'] = pd.to_datetime(covid['Date'])
        covid = covid.reset_index(drop=True)
        covid = covid.set_index(['Date'], drop=True)

        # Clean up trend columns
        trend = trend.drop(columns='isPartial')

        self.clean_data_frame = [covid, trend]

    def aggregate_data(self):
        """
        This function combines the two data sets in a join on the two
        dataframes. Then it cleans this larger data frame, addressing
        gaps in the data that emerge as a result of the data join.
        Inputs:
            - None: The object's attribute clean_data_frame is used
        Outputs:
            - agg_data_frame: a single dataframe containing all the data
            needed for visualization combined in to one ddata frame
        """

        # Variable Assignments
        covid = self.clean_data_frame[0]
        trend = self.clean_data_frame[1]

        # Join and update indices
        agg = covid.join(trend, how='outer')
        agg.reset_index(inplace=True)
        agg = agg.rename(columns={'index': 'Date'})

        # Forward Fill in non-existent values for google trends
        # Based on keyword arguments
        number_of_keywords = len(self.args)
        for i in range(number_of_keywords):
            agg[self.args[i]].fillna(method='ffill', inplace=True)

        # Forward Fill missing covid data with values
        agg.iloc[0, agg.columns.get_loc('Confirmed')] = 0
        agg['Confirmed'].fillna(method='ffill', inplace=True)

        agg.iloc[0, agg.columns.get_loc('ConfirmedChange')] = 0
        agg['ConfirmedChange'].fillna(method='ffill', inplace=True)

        agg.iloc[0, agg.columns.get_loc('Deaths')] = 0
        agg['Deaths'].fillna(method='ffill', inplace=True)

        agg.iloc[0, agg.columns.get_loc('DeathsChange')] = 0
        agg['DeathsChange'].fillna(method='ffill', inplace=True)

        agg.iloc[0, agg.columns.get_loc('Recovered')] = 0
        agg['Recovered'].fillna(method='ffill', inplace=True)

        agg.iloc[0, agg.columns.get_loc('RecoveredChange')] = 0
        agg['RecoveredChange'].fillna(method='ffill', inplace=True)

        # Forward and backfill State and Country data
        # This is to ensure all cells are filled with valid country and state
        agg['Country'].fillna(method='ffill', inplace=True)
        agg['Country'].fillna(method='bfill', inplace=True)
        agg['State'].fillna(method='ffill', inplace=True)
        agg['State'].fillna(method='bfill', inplace=True)

        self.agg_data_frame = agg
        